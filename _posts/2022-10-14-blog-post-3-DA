# EDA

My overall goal when doing an EDA is to let the data lead the way in the investigation and to try and minimize my own ideas or preconceived notions about what I might find before I begin the analysis. I think that it is very important to understand the types of variables that you are dealing with before you begin any analysis or visualization. Gathering as much information as possible about each variable beforehand and in the initial steps of an EDA can help to focus your analysis in later steps.  

In addition to understanding the specific variables in question, it is very important to understand as much as possible about how this data was collected as well as to try and understand what missing values might be telling you about a specific variable. Is there a way that we might convert these NA values into something more useful while still maintaining the integrity of our dataset? Sometimes it might be useful to create another option for a variable in question to take the place of an NA value. In working with a dataset from the National Parks API I had access to information about cell service availability for all campgrounds in the National Parks system. This variable returned either “no”, “yes - seasonal”, or “yes - year round”. There were only a few missing values in the dataset for this variable. To make analysis a little easier to visualize and understand without wholesale removal of NA values, I instead labeled these missing values as “unknown”. This allowed for the creation of tables and plots comparing this information, while still allowing us to account for the NA values. A similar idea could be applied to information obtained in surveys where NA values correspond to non-response to a survey question or other instances where the NA values could actually be lending information about the method of data collection itself.

During the EDA it is also important to identify outliers and to hopefully get a better understanding of what the cause of this outlier might be. Is an outlier in the data the result of a data entry error or a difference in how this particular data point was gathered? Can we remove the outlier from our analysis? Again, taking the National Parks campground information into account, in looking at a variable called “total sites”, which recorded campsites contained in a campground, there appeared to be a single, but very substantial outlier with a value of 5000. The next highest number of campsites was less than one tenth of this value. When investigating this outlier I discovered that this value was from a site in Glen Canyon National Recreation Area in Utah called “Lone Rock Beach Primitive Camping Area”.  This is an undeveloped area that is open to camping but without any official designated campsites. The information about the campsites in this campground only took on extreme values as compared to how data for other campgrounds in the data set was entered, taking on values of 0 or very large values of 5000, 10,000, etc. As a result of this quick investigation into this outlier, it appeared to be a result of a different way that data was reported at this particular campground, as opposed to a real difference in the total sites variable itself.

Lastly, a quick overview of correlation between variables can point to areas that might warrant further investigation. With smaller datasets with fewer numbers of variables this might be accomplished through the creation of scatter plots to get a sense of what is going on with our data. With larger data sets it might make more sense to run a correlation matrix to identify relationships among variables that might be of interest. 
