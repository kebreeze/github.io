# Project 3 Blog Post  

[Link to rendered site](https://kebreeze.github.io/558Project3/)  

[Link to repo](https://github.com/kebreeze/558Project3.git)  

For this project we created models to predict the number of shares for different types of online news articles.  We created four different models, a random forest model, a boosted forest model, and two different linear models. We also created code to select the best model according to MSE on the training data set.  The last step was to automate this process for six different data channels, automatically selecting the best model and generating a report for each.  

I think that overall the workflow of the project went pretty well between my partner and I. I am still getting used to using github to collaborate, but I feel like I am getting the hang of things a bit.  I would not change too much about how the project went this time.  

The most difficult part was getting the automation to work. In the beginning I was trying to get the automation to work and I had the script inside of the original .Rmd file. This created an endless loop that I spend way too much time waiting to finish before realizing something was wrong. I also realized that to figure out the automation part everything could be done fairly quickly if I commented out some of the more intensive code chunks (like the random forest and boosted tree models) and then tinkered with the automation of reports. I also forgot about the fact that you need to save the .Rmd file if you make changes and want to render the file again. 

The big takeaways that I had from this project were:  

1.  GitHub is really useful for collaboration and version control  
2.  Always save .Rmd file before rendering  
3.  When working with computationally intensive code and automation it is best to comment out the intensive code chunks while getting the automation to work, and then adding those code chunks back in once the automation has been finalized.  


